{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5457acc-093a-4d4c-b828-b3e5d23d99b1",
   "metadata": {},
   "source": [
    "# Tic-tac-toe minmax algorithm with search limits\n",
    "We will demonstrate the minmax algorithm on a game played on a 3x3 game board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f52a5e-f1a6-4381-8f90-ccc2cad21c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f788e6",
   "metadata": {},
   "source": [
    "The State class captures the current state of the game.\n",
    "* **Attributes**\n",
    "    * gameplan - 3x3 game board with values 0 to 2\n",
    "    * player - the player who is currently on the turn\n",
    "    * current_player - the player will analyze the game and keep track of possible new states. Players take turns, so the new state should be viewed from the perspective of the opposing player. the player who is on the turn in the current state when searching the state space\n",
    "    * depth - the depth of the analyzed state\n",
    "    * max_depth - how many moves ahead the maximum is looking. If depth = max_depth, I don't analyze the game any further.\n",
    "\n",
    "* **Methods**\n",
    "    * terminal_test - method returns information whether the current state is final or not. If it is, it returns the winner.\n",
    "    * utility - the method tries to evaluate the current state from the player's perspective. In the basic version, it only distinguishes whether the player wins, doesn't win or the move doesn't lead to the end of the game.\n",
    "    * possible_actions - the method returns a list of possible moves. In the case of biscuits, this will be the coordinates of the playing area where the playing stone can be placed.\n",
    "    * expand - this method takes the current state and action definition (the coordinates where to place the die) and creates a new game state.\n",
    "    * minmax - custom implementation of the minmax algorithm\n",
    "    * next_current_player - returns the opponent to the current_player variable\n",
    "    * next_player - returns the opponents to the player variable    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3b7b390-57e3-4256-b28d-4d7d3e73a92f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Tic-Tac-Toe Minimax Search Depth Tests\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ðŸ“Š Results Comparison\n",
      "==================================================\n",
      "| Constraint (D) | Game Result | Total Time (s) | Generated States |\n",
      "|---------------|-------------|-----------------|------------------|\n",
      "| D=2         | Player 1 Wins | 0.0083 s | 89              |\n",
      "| D=4         | Player 1 Wins | 0.1765 s | 4064            |\n",
      "| D=9         | Drawn       | 22.9571 s | 618175          |\n",
      "==================================================\n",
      "\n",
      "**Observation Summary:** As the depth limit decreases, time and the number of generated states drop rapidly, but the game outcome may deviate from the optimal (draw) result.\n"
     ]
    }
   ],
   "source": [
    "class State:\n",
    "    \"\"\" Capturing the state of the game\n",
    "    gameplan - two-dimensional 3x3 array (0: empty, 1: X, 2: O)\n",
    "    player - the player who has the turn in the game\n",
    "    current_player - player who is on the turn in the given state when searching the state space\n",
    "    depth - depth of the state space search\n",
    "    max_depth - maximum length of the search\n",
    "    \"\"\"\n",
    "\n",
    "    generated = 0\n",
    "\n",
    "    def __init__(self, gameplan, player, current_player=None, depth=0, max_depth=3):\n",
    "        self.gameplan = gameplan\n",
    "        self.player = player\n",
    "        if current_player is None:\n",
    "            self.current_player = player\n",
    "        else:\n",
    "            self.current_player = current_player\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        State.generated += 1\n",
    "\n",
    "    def terminal_test(self):\n",
    "        \"\"\" The method tests the current state and returns a value indicating whether the game is finished and, if so, who the winner is\n",
    "            0 - no final status (game continues)\n",
    "            1 - Player 1 wins\n",
    "            2 - Player 2 wins\n",
    "            -1 - Draw\n",
    "        \"\"\"\n",
    "        # Horizontal and Vertical Check\n",
    "        for i in range(3):\n",
    "            if np.array_equal(self.gameplan[i], [1, 1, 1]) or np.array_equal(self.gameplan[:, i], [1, 1, 1]):\n",
    "                return 1\n",
    "            if np.array_equal(self.gameplan[i], [2, 2, 2]) or np.array_equal(self.gameplan[:, i], [2, 2, 2]):\n",
    "                return 2\n",
    "\n",
    "        # Diagonal Check\n",
    "        if np.array_equal(self.gameplan.diagonal(), [1, 1, 1]) or np.array_equal(np.fliplr(self.gameplan).diagonal(), [1, 1, 1]):\n",
    "            return 1\n",
    "        if np.array_equal(self.gameplan.diagonal(), [2, 2, 2]) or np.array_equal(np.fliplr(self.gameplan).diagonal(), [2, 2, 2]):\n",
    "            return 2\n",
    "        \n",
    "        # Draw Check: If no winner and no empty spaces\n",
    "        if 0 not in self.gameplan:\n",
    "            return -1 \n",
    "\n",
    "        return 0 # Game continues\n",
    "\n",
    "    def utility(self, result):\n",
    "        \"\"\" The method returns an evaluation of the current state of the game\n",
    "            (from the perspective of the original player self.player)\n",
    "        \"\"\"\n",
    "        if result == -1: # Draw\n",
    "            return 0\n",
    "        elif result == self.player: # Original player wins\n",
    "            return 1\n",
    "        else: # Opponent wins\n",
    "            return -1\n",
    "\n",
    "    def possible_actions(self):\n",
    "        \"\"\" The method returns a list of possible actions (coordinates of empty fields). \"\"\"\n",
    "        possible_actions = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.gameplan[i][j] == 0:\n",
    "                    possible_actions.append((i, j))\n",
    "        return possible_actions\n",
    "\n",
    "    def expand(self, select_action):\n",
    "        \"\"\" Creates a new game state by applying the action. \"\"\"\n",
    "        if select_action[0] not in range(3) or select_action[1] not in range(3) or self.gameplan[select_action[0], select_action[1]] != 0:\n",
    "            return None\n",
    "        \n",
    "        new_array = np.copy(self.gameplan)\n",
    "        new_array[select_action[0], select_action[1]] = self.current_player \n",
    "        \n",
    "        return State(new_array, \n",
    "                     self.player, \n",
    "                     self.next_current_player(), \n",
    "                     self.depth + 1, \n",
    "                     max_depth=self.max_depth)\n",
    "        \n",
    "    def minmax(self, strategy=\"max\"):\n",
    "        \"\"\" The depth-limited Minimax algorithm. \"\"\"\n",
    "        \n",
    "        # 1. Check for Terminal State (Win/Loss/Draw)\n",
    "        result = self.terminal_test()\n",
    "        actions = self.possible_actions()\n",
    "        \n",
    "        if result != 0: \n",
    "            # Game ended, return utility score and a dummy action\n",
    "            return self.utility(result), actions[0] if actions else None\n",
    "        \n",
    "        # 2. **APPLY MAXIMUM DEPTH RESTRICTION**\n",
    "        if self.depth >= self.max_depth:\n",
    "            # Max depth reached, stop search and return heuristic evaluation (0 for draw/undecided)\n",
    "            return 0, actions[0] if actions else None\n",
    "\n",
    "        # 3. Initialization\n",
    "        if strategy == \"max\":\n",
    "            selected_utilization_value = float('-inf')\n",
    "            next_strategy = \"min\"\n",
    "        else: \n",
    "            selected_utilization_value = float('inf')\n",
    "            next_strategy = \"max\"\n",
    "\n",
    "        if not actions:\n",
    "            return 0, None # Safety check for draw\n",
    "            \n",
    "        selected_action = actions[0]\n",
    "\n",
    "        # 4. Search Loop\n",
    "        for action in actions:\n",
    "            expanded_state = self.expand(action)\n",
    "            \n",
    "            # Recursive Call\n",
    "            utilization, _ = expanded_state.minmax(next_strategy)\n",
    "\n",
    "            # 5. Update based on strategy\n",
    "            if strategy == \"max\":\n",
    "                if utilization > selected_utilization_value:\n",
    "                    selected_utilization_value = utilization\n",
    "                    selected_action = action\n",
    "            else: # strategy == \"min\"\n",
    "                if utilization < selected_utilization_value:\n",
    "                    selected_utilization_value = utilization\n",
    "                    selected_action = action\n",
    "\n",
    "        return selected_utilization_value, selected_action\n",
    "\n",
    "    def next_current_player(self):\n",
    "        \"\"\" Returns the opponent for the state space searching. \"\"\"\n",
    "        return 3 - self.current_player\n",
    "\n",
    "    def next_player(self):\n",
    "        \"\"\" Returns the opponent for the actual game turn. \"\"\"\n",
    "        return 3 - self.player\n",
    "\n",
    "\n",
    "#test\n",
    "\n",
    "def run_game(max_depth):\n",
    "    \"\"\" Runs a game with the specified max_depth and returns metrics. \"\"\"\n",
    "    State.generated = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize the state (Game plan is empty, P1 starts)\n",
    "    state = State(gameplan=np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]]),\n",
    "                  player=1, max_depth=max_depth)\n",
    "    \n",
    "    total_generated = 0\n",
    "    game_result = 0 # 0: Continue, 1: P1 Win, 2: P2 Win, -1: Draw\n",
    "\n",
    "    while True:\n",
    "        game_result = state.terminal_test()\n",
    "        if game_result != 0:\n",
    "            break\n",
    "\n",
    "        # Current player's move (always uses \"max\" strategy)\n",
    "        State.generated = 0\n",
    "        _, player_action = state.minmax(\"max\") \n",
    "        total_generated += State.generated\n",
    "        \n",
    "        if player_action is None:\n",
    "             game_result = -1 \n",
    "             break\n",
    "\n",
    "        state = state.expand(player_action)\n",
    "        \n",
    "        # Switching the game turn to the other player\n",
    "        state.player = state.next_player()\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    if game_result == -1:\n",
    "        winner = \"Drawn\"\n",
    "    elif game_result == 1 or game_result == 2:\n",
    "        winner = f\"Player {game_result} Wins\"\n",
    "    else:\n",
    "        winner = \"Unknown\"\n",
    "        \n",
    "    return winner, duration, total_generated\n",
    "\n",
    "# --- Run Tests ---\n",
    "depths_to_test = [2, 4, 9] \n",
    "results = {}\n",
    "\n",
    "print(\"ðŸš€ Tic-Tac-Toe Minimax Search Depth Tests\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for depth in depths_to_test:\n",
    "    winner, duration, generated_states = run_game(depth)\n",
    "    results[depth] = {\n",
    "        \"winner\": winner,\n",
    "        \"time\": duration,\n",
    "        \"generated_states\": generated_states\n",
    "    }\n",
    "\n",
    "# --- Results Comparison ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ“Š Results Comparison\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"| Constraint (D) | Game Result | Total Time (s) | Generated States |\")\n",
    "print(\"|---------------|-------------|-----------------|------------------|\")\n",
    "for depth, data in results.items():\n",
    "    print(f\"| D={depth:<10}| {data['winner']:<11} | {data['time']:.4f} s | {data['generated_states']:<16}|\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n**Observation Summary:** As the depth limit decreases, time and the number of generated states drop rapidly, but the game outcome may deviate from the optimal (draw) result.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340d3be-f984-4633-9453-dca5ee8dc29a",
   "metadata": {},
   "source": [
    "# Task\n",
    "- Add a constraint to the algorithm to limit the maximum search depth.\n",
    "- Try different search depth constraints.\n",
    "- Observe how the times and numbers of generated states change\n",
    "- Are the game results changing?\n",
    "\n",
    "You need to implement a limitation on the # !!! todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d737250e-a504-40ce-a300-27b984c0f642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Player 1\n",
      "Select action: (0, 0)\n",
      "[[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Generated states 85.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (0, 1)\n",
      "[[1 2 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Generated states 9.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (0, 2)\n",
      "[[1 2 1]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Generated states 1.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (1, 0)\n",
      "[[1 2 1]\n",
      " [2 0 0]\n",
      " [0 0 0]]\n",
      "Generated states 1.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (1, 1)\n",
      "[[1 2 1]\n",
      " [2 1 0]\n",
      " [0 0 0]]\n",
      "Generated states 1.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (1, 2)\n",
      "[[1 2 1]\n",
      " [2 1 2]\n",
      " [0 0 0]]\n",
      "Generated states 1.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (2, 0)\n",
      "[[1 2 1]\n",
      " [2 1 2]\n",
      " [1 0 0]]\n",
      "Generated states 1.\n",
      "Winner is 1 \n"
     ]
    }
   ],
   "source": [
    "# Creating the initial state of the game\n",
    "    # Game plan is empty\n",
    "    # the turn is player 1\n",
    "state = State(gameplan=np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]]),\n",
    "              player=1, max_depth=2)\n",
    "# Cycle for a game where two copies of the algorithm play against each other\n",
    "while True:\n",
    "    # Check if the game is not over\n",
    "    game_result = state.terminal_test()\n",
    "    if game_result != 0:\n",
    "        print(f\"Winner is {game_result} \")\n",
    "        break\n",
    "\n",
    "    # Checking for drawn\n",
    "    if len(state.possible_actions()) == 0:\n",
    "        print(\"Drawn\")\n",
    "        break\n",
    "\n",
    "    # player move\n",
    "    print(f\"=====================\\nPlayer {state.player}\")\n",
    "    _, player_action = state.minmax(\"max\")\n",
    "    print(f\"Select action: {player_action}\")\n",
    "    state = state.expand(player_action)\n",
    "    print(state.gameplan)\n",
    "    print(f\"Generated states {State.generated}.\")\n",
    "    State.generated = 0\n",
    "\n",
    "    # switching the game to the other player\n",
    "    state.player = state.next_player()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
