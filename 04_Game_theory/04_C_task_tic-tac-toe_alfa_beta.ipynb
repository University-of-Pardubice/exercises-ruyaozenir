{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5457acc-093a-4d4c-b828-b3e5d23d99b1",
   "metadata": {},
   "source": [
    "# Tic-tac-toe minmax algorithm with alpha beta pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07f52a5e-f1a6-4381-8f90-ccc2cad21c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1291ef",
   "metadata": {},
   "source": [
    "The original code has been extended with the implementation of the minmax algorithm and with alpha beta pruning.\n",
    "\n",
    "The **minmax** method has been changed to now have alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3b7b390-57e3-4256-b28d-4d7d3e73a92f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class State:\n",
    "    \"\"\" Capturing the state of the game\n",
    "    gameplan - 3x3 array (0: Empty, 1: X, 2: O)\n",
    "    player - The player whose turn it is in the game.\n",
    "    current_player - The player currently being evaluated in the search tree.\n",
    "    depth - Current depth in the search tree.\n",
    "    max_depth - Maximum search limit.\n",
    "    \"\"\"\n",
    "\n",
    "    generated = 0\n",
    "\n",
    "    def __init__(self, gameplan, player, current_player=None, depth=0, max_depth=100):\n",
    "        self.gameplan = np.copy(gameplan) \n",
    "        self.player = player\n",
    "        if current_player is None:\n",
    "            self.current_player = player\n",
    "        else:\n",
    "            self.current_player = current_player\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        State.generated += 1\n",
    "\n",
    "    def terminal_test(self):\n",
    "        \"\"\" The method tests the current state and returns the winner if the game is over.\n",
    "            0 - Draw / Game continues\n",
    "            1 - Player 1 wins\n",
    "            2 - Player 2 wins\n",
    "        \"\"\"\n",
    "        # Winning conditions (Rows, Columns)\n",
    "        for i in range(3):\n",
    "            if np.array_equal(self.gameplan[i], [1, 1, 1]): return 1\n",
    "            if np.array_equal(self.gameplan[i], [2, 2, 2]): return 2\n",
    "            if np.array_equal(self.gameplan[:, i], [1, 1, 1]): return 1\n",
    "            if np.array_equal(self.gameplan[:, i], [2, 2, 2]): return 2\n",
    "        \n",
    "        # Winning conditions (Diagonals)\n",
    "        if np.array_equal(self.gameplan.diagonal(), [1, 1, 1]): return 1\n",
    "        if np.array_equal(self.gameplan.diagonal(), [2, 2, 2]): return 2\n",
    "        if np.array_equal(np.fliplr(self.gameplan).diagonal(), [1, 1, 1]): return 1\n",
    "        if np.array_equal(np.fliplr(self.gameplan).diagonal(), [2, 2, 2]): return 2\n",
    "\n",
    "        # Draw check\n",
    "        if 0 not in self.gameplan:\n",
    "            return 0 # Draw\n",
    "        return 0 # Game continues\n",
    "\n",
    "    def utility(self, result):\n",
    "        \"\"\" The method evaluates the current state from the perspective of self.player.\n",
    "            1: self.player wins, -1: Opponent wins, 0: Draw\n",
    "        \"\"\"\n",
    "        if result == 0: return 0\n",
    "        elif result == self.player: return 1\n",
    "        else: return -1\n",
    "\n",
    "    def possible_actions(self):\n",
    "        \"\"\" The method returns a list of possible actions (empty coordinates). \"\"\"\n",
    "        actions = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.gameplan[i][j] == 0:\n",
    "                    actions.append((i, j))\n",
    "        return actions\n",
    "\n",
    "    def expand(self, select_action):\n",
    "        \"\"\" Creates a new game state by applying the selected action. \"\"\"\n",
    "        # Coordinate checks\n",
    "        if select_action[0] not in range(3) or select_action[1] not in range(3): return None\n",
    "        if self.gameplan[select_action[0], select_action[1]] != 0: return None\n",
    "        \n",
    "        new_array = np.copy(self.gameplan)\n",
    "        new_array[select_action[0], select_action[1]] = self.current_player\n",
    "        \n",
    "        # New state is returned with the opponent as the next current_player\n",
    "        return State(new_array, \n",
    "                     self.player, \n",
    "                     self.next_current_player(), \n",
    "                     self.depth + 1, \n",
    "                     max_depth=self.max_depth)\n",
    "\n",
    "    def minmax(self, strategy=\"max\", alfa=float('-inf'), beta= float('inf')):\n",
    "        \"\"\"\n",
    "        Minimax algorithm implementation with Alpha-Beta pruning and depth limit.\n",
    "        \"\"\"\n",
    "        \n",
    "        actions = self.possible_actions()\n",
    "        result = self.terminal_test()\n",
    "        \n",
    "        # 1. BASE CASE: TERMINAL TEST OR DEPTH LIMIT\n",
    "        if result != 0 or self.depth >= self.max_depth: \n",
    "            # If game is over OR Max Depth is reached\n",
    "            # Score is calculated. Action is insignificant, return an available action.\n",
    "            score = self.utility(result) if result != 0 else 0 \n",
    "            return score, actions[0] if actions else (0, 0)\n",
    "\n",
    "\n",
    "        # 2. INITIALIZATION\n",
    "        if strategy == \"max\":\n",
    "            selected_utilization_value = float('-inf')\n",
    "            next_strategy = \"min\"\n",
    "        else:\n",
    "            selected_utilization_value = float('inf')\n",
    "            next_strategy = \"max\"\n",
    "\n",
    "        if not actions: \n",
    "             return 0, (0, 0) # Should be caught by terminal_test\n",
    "\n",
    "        selected_action = actions[0]\n",
    "\n",
    "        # 3. RECURSIVE SEARCH WITH PRUNING\n",
    "        for action in actions:\n",
    "            expanded_state = self.expand(action)\n",
    "            \n",
    "            # Recursive call (passing updated alpha and beta)\n",
    "            utilization, _ = expanded_state.minmax(next_strategy, alfa, beta)\n",
    "            \n",
    "            # MAXIMIZER (Player X)\n",
    "            if strategy == \"max\":\n",
    "                if utilization > selected_utilization_value:\n",
    "                    selected_utilization_value = utilization\n",
    "                    selected_action = action\n",
    "                \n",
    "                # ALPHA UPDATE\n",
    "                alfa = max(alfa, selected_utilization_value)\n",
    "                \n",
    "                # BETA PRUNING (Cutoff)\n",
    "                if selected_utilization_value >= beta:\n",
    "                    return selected_utilization_value, selected_action\n",
    "            \n",
    "            # MINIMIZER (Player O)\n",
    "            else: # strategy == \"min\"\n",
    "                if utilization < selected_utilization_value:\n",
    "                    selected_utilization_value = utilization\n",
    "                    selected_action = action\n",
    "                    \n",
    "                # BETA UPDATE\n",
    "                beta = min(beta, selected_utilization_value)\n",
    "\n",
    "                # ALPHA PRUNING (Cutoff)\n",
    "                if selected_utilization_value <= alfa:\n",
    "                    return selected_utilization_value, selected_action\n",
    "            \n",
    "        return selected_utilization_value, selected_action\n",
    "\n",
    "    def next_current_player(self):\n",
    "        \"\"\" Returns the opponent for the purpose of traversing the search space. \"\"\"\n",
    "        return 3 - self.current_player\n",
    "\n",
    "    def next_player(self):\n",
    "        \"\"\" Returns the opponent for switching the game turn. \"\"\"\n",
    "        return 3 - self.player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10d826",
   "metadata": {},
   "source": [
    "# Game of tic-tac-toe\n",
    "\n",
    "Creating the initial state of the game\n",
    "* Game plan is empty (0)\n",
    "* Game 1 is on the turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1b4adca-e8bf-4977-a89a-bd44d5f8e602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state = State(gameplan=np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]]),\n",
    "              player=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1589681",
   "metadata": {},
   "source": [
    "The cycle of the game remained unchanged. \n",
    "\n",
    "Run the turn and compare the result of the turn, times and numbers of generated states against the original minmax version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b06d9a-a759-450f-922d-59515d8aac81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Game (Max Depth: 9) ---\n",
      "Player 1 move: (0, 0) -> Utility (for P1): 0\n",
      "[[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Player 2 move: (1, 1) -> Utility (for P2): 0\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Player 1 move: (0, 1) -> Utility (for P1): 0\n",
      "[[1 1 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Player 2 move: (0, 2) -> Utility (for P2): 0\n",
      "[[1 1 2]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Player 1 move: (2, 0) -> Utility (for P1): 0\n",
      "[[1 1 2]\n",
      " [0 2 0]\n",
      " [1 0 0]]\n",
      "Player 2 move: (1, 0) -> Utility (for P2): 0\n",
      "[[1 1 2]\n",
      " [2 2 0]\n",
      " [1 0 0]]\n",
      "Player 1 move: (1, 2) -> Utility (for P1): 0\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 0 0]]\n",
      "Player 2 move: (2, 1) -> Utility (for P2): 0\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 2 0]]\n",
      "Player 1 move: (2, 2) -> Utility (for P1): 0\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 2 1]]\n",
      "Result: Drawn\n",
      "Total States Generated: 21653\n",
      "Total Time: 0.9423s\n",
      "---------------------------------------\n",
      "\n",
      "--- Running Game (Max Depth: 4) ---\n",
      "Player 1 move: (0, 0) -> Utility (for P1): 0\n",
      "[[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Player 2 move: (0, 1) -> Utility (for P2): 0\n",
      "[[1 2 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Player 1 move: (0, 2) -> Utility (for P1): 0\n",
      "[[1 2 1]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Player 2 move: (1, 0) -> Utility (for P2): 0\n",
      "[[1 2 1]\n",
      " [2 0 0]\n",
      " [0 0 0]]\n",
      "Player 1 move: (1, 1) -> Utility (for P1): 0\n",
      "[[1 2 1]\n",
      " [2 1 0]\n",
      " [0 0 0]]\n",
      "Player 2 move: (1, 2) -> Utility (for P2): 0\n",
      "[[1 2 1]\n",
      " [2 1 2]\n",
      " [0 0 0]]\n",
      "Player 1 move: (2, 0) -> Utility (for P1): 0\n",
      "[[1 2 1]\n",
      " [2 1 2]\n",
      " [1 0 0]]\n",
      "Result: Winner is 1\n",
      "Total States Generated: 314\n",
      "Total Time: 0.0172s\n",
      "---------------------------------------\n",
      "\n",
      "--- Running Game (Max Depth: 2) ---\n",
      "Player 1 move: (0, 0) -> Utility (for P1): 0\n",
      "[[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Player 2 move: (0, 1) -> Utility (for P2): 0\n",
      "[[1 2 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Player 1 move: (0, 2) -> Utility (for P1): 0\n",
      "[[1 2 1]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Player 2 move: (1, 0) -> Utility (for P2): 0\n",
      "[[1 2 1]\n",
      " [2 0 0]\n",
      " [0 0 0]]\n",
      "Player 1 move: (1, 1) -> Utility (for P1): 0\n",
      "[[1 2 1]\n",
      " [2 1 0]\n",
      " [0 0 0]]\n",
      "Player 2 move: (1, 2) -> Utility (for P2): 0\n",
      "[[1 2 1]\n",
      " [2 1 2]\n",
      " [0 0 0]]\n",
      "Player 1 move: (2, 0) -> Utility (for P1): 0\n",
      "[[1 2 1]\n",
      " [2 1 2]\n",
      " [1 0 0]]\n",
      "Result: Winner is 1\n",
      "Total States Generated: 41\n",
      "Total Time: 0.0027s\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TEST FUNCTION\n",
    "def run_game(max_d):\n",
    "    \"\"\"\n",
    "    Runs a game of Tic-Tac-Toe using the Minimax algorithm with a specified \n",
    "    maximum search depth (max_d), observing game result, time, and states generated.\n",
    "    \"\"\"\n",
    "    # Reset generation count and timer\n",
    "    State.generated = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize the game state. P1 starts.\n",
    "    state = State(gameplan=np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]]),\n",
    "                  player=1, \n",
    "                  current_player=1, # Initial player makes the first move\n",
    "                  max_depth=max_d)\n",
    "    \n",
    "    print(f\"\\n--- Running Game (Max Depth: {max_d}) ---\")\n",
    "    \n",
    "    while True:\n",
    "        # 1. PRE-MOVE CHECK\n",
    "        game_result = state.terminal_test()\n",
    "        actions_available = len(state.possible_actions())\n",
    "        \n",
    "        if game_result != 0 or actions_available == 0:\n",
    "            winner_text = \"Drawn\" if game_result == 0 else f'Winner is {game_result}'\n",
    "            print(f\"Result: {winner_text}\")\n",
    "            break\n",
    "\n",
    "        current_player = state.player\n",
    "        \n",
    "        # Set the state's internal evaluation perspective (self.player) to the current player \n",
    "        # so that utility results are calculated from *their* viewpoint (+1 is a win for them).\n",
    "        original_eval_player = state.player \n",
    "        state.player = current_player \n",
    "        \n",
    "        # Set the current_player for the search root\n",
    "        state.current_player = current_player \n",
    "\n",
    "        # Minimax always maximizes the outcome for the player whose turn it is.\n",
    "        util, player_action = state.minmax(\"max\")\n",
    "        \n",
    "        # Restore the permanent evaluation player (P1 in the original game setup)\n",
    "        state.player = original_eval_player \n",
    "\n",
    "        # 3. APPLY MOVE (Uses state.current_player to determine the piece to place)\n",
    "        state = state.expand(player_action) \n",
    "        \n",
    "        print(f\"Player {current_player} move: {player_action} -> Utility (for P{current_player}): {util}\")\n",
    "        print(state.gameplan)\n",
    "        \n",
    "        # 4. SWITCH TURN\n",
    "        # Switch the actual game turn for the next iteration.\n",
    "        state.player = state.next_player() \n",
    "        # Set the next current_player for the next turn's root search.\n",
    "        state.current_player = state.player \n",
    "\n",
    "    # 5. REPORT RESULTS\n",
    "    end_time = time.time()\n",
    "    print(f\"Total States Generated: {State.generated}\")\n",
    "    print(f\"Total Time: {end_time - start_time:.4f}s\")\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "\n",
    "# Run the game with different search depth constraints to compare performance.\n",
    "run_game(max_d=9) # Max Depth 9: Full Search (Optimal) \n",
    "run_game(max_d=4) # Constrained Depth 4\n",
    "run_game(max_d=2) # Very Limited Depth 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340d3be-f984-4633-9453-dca5ee8dc29a",
   "metadata": {},
   "source": [
    "# Task\n",
    "Add a constraint to the algorithm to limit the maximum search depth.\n",
    "\n",
    "Again, you need to change the code in place of # **!!! todo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c11d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = State(gameplan=np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]]),\n",
    "              player=1, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48b0a648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner is 1 \n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Check that the game is not over\n",
    "    game_result = state.terminal_test()\n",
    "    if game_result != 0:\n",
    "        print(f\"Winner is {game_result} \")\n",
    "        break\n",
    "\n",
    "    # Checking for drawn\n",
    "    if len(state.possible_actions()) == 0:\n",
    "        print(\"Drawn\")\n",
    "        break\n",
    "\n",
    "    # player's move\n",
    "    print(f\"=====================\\nPlayer {state.player}\")\n",
    "    _, player_action = state.minmax(\"max\")\n",
    "    print(f\"Select action: {player_action}\")\n",
    "    state = state.expand(player_action)\n",
    "    print(state.gameplan)\n",
    "    print(f\"Generated states {State.generated}.\")\n",
    "    State.generated = 0\n",
    "\n",
    "    # switching the game to the other player\n",
    "    state.player = state.next_player()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
